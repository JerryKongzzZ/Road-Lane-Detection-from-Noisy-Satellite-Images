{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.3' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.3' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.3' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Debug mode if i = 0\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.3' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "output_dir = 'output'\n",
    "test_dir = 'C:\\example\\Test_studentversion\\images'\n",
    "\n",
    "if(i == 1):\n",
    "    train_img_folder = 'C:/example/Train/Train/images'\n",
    "    train_gt_folder = 'C:/example/Train/Train/labels'\n",
    "else:\n",
    "    train_img_folder = 'C:/example/Train/Train/labels_test'\n",
    "    train_gt_folder = 'C:/example/Train/Train/images_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.3' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms  \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "if(not os.path.exists(train_img_folder)):\n",
    "    print('Folder not exists')\n",
    "if(not os.path.exists(train_gt_folder)):\n",
    "    print('Folder not exists')\n",
    "\n",
    "print(\"Start Training.....\")\n",
    "\n",
    "# Custom dataset for image segmentation\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.images = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.images[index]\n",
    "        img_path = os.path.join(self.image_dir, img_name)#.replace('sat.jpg', 'mask.png'))\n",
    "        mask_path = os.path.join(self.mask_dir, img_name.replace('mask.png', 'sat.jpg'))\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform['image'](image)\n",
    "            mask = self.transform['mask'](mask)\n",
    "\n",
    "        return image, mask, img_name\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.images = os.listdir(image_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        image = preprocess(image)\n",
    "        \n",
    "        return image, self.images[index]\n",
    "\n",
    "# Use plt.imshow to visualize images and masks\n",
    "def show_image_mask(num1, num2, label):\n",
    "    plt.clf() # Clean the current figure\n",
    "    plt.title(label)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.plot(num1, label='Accuracy')\n",
    "    plt.plot(num2, label='Loss')\n",
    "    plt.legend(loc='right')\n",
    "    plt.show()\n",
    "\n",
    "# Define transformations for images and masks\n",
    "transform = {\n",
    "    'image': transforms.Compose([\n",
    "        transforms.Resize((256,256)),  # Resize images\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'mask': transforms.Compose([\n",
    "        transforms.Resize((256,256)),  # Resize masks to match images\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "train_data = SegmentationDataset(train_img_folder, train_gt_folder, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=3, shuffle=True)\n",
    "\n",
    "# Simple CNN model for segmentation\n",
    "class SimpleSegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleSegmentationModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # Adjusted input channels to 3 for RGB\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv6 = nn.Conv2d(64, 1, kernel_size=4, stride=4)  # Output is 1 channel for mask\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.upsample(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.upsample(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.upsample(x)\n",
    "        x = torch.sigmoid(self.conv6(x))  # Use sigmoid for binary classification\n",
    "        return x\n",
    "\n",
    "def value_accuracy(outputs, masks):\n",
    "    outputs = outputs > 0.5\n",
    "    masks = masks > 0.5\n",
    "    correct = torch.sum(outputs == masks).item()\n",
    "    total = outputs.numel()\n",
    "    return correct / total\n",
    "\n",
    "# Function to save the model\n",
    "def save_checkpoint(model, epoch, checkpoint_dir='checkpoints'):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{epoch}.pth')\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    return checkpoint_path\n",
    "\n",
    "def test_model(model_path):\n",
    "    test_data = TestDataset(test_dir)\n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "    model = SimpleSegmentationModel()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    device = 'cuda'\n",
    "    model.to(device)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print('Testing model...')\n",
    "    with torch.no_grad():\n",
    "        for images, image_names in test_loader:\n",
    "            t = 0\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            for output, image_name in zip(outputs, image_names):\n",
    "                t += 1\n",
    "                output = output.squeeze().cpu().numpy()\n",
    "                output = (output * 255).astype('uint8')\n",
    "                output_image = Image.fromarray(output)\n",
    "                output_path = os.path.join(output_dir, image_name)\n",
    "                output_image.save(output_path)\n",
    "\n",
    "# Setup device, model, loss function, and optimizer\n",
    "device = torch.device('cuda')\n",
    "print(f'Device: {device}')\n",
    "model = SimpleSegmentationModel().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "checkpoint_path = ''\n",
    "total_loss = 0\n",
    "arr_acc = []\n",
    "arr_loss = []\n",
    "total_acc = 0\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    total_num = len(train_loader)\n",
    "    if (checkpoint_path != ''):\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_loader, unit='batch')\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    for images, masks, image_names in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)  # Adjust mask dimensions if necessary\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.update()\n",
    "        total_acc += value_accuracy(outputs, masks)\n",
    "    sleep(0.5)\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        model_path = save_checkpoint(model, epoch + 1)\n",
    "    progress_bar.close()\n",
    "    test_model(model_path)\n",
    "    print(f'Loss: {total_loss/total_num:.4f} Value_Accuracy: {total_acc/total_num:.4f}')\n",
    "    arr_acc.append(total_acc/total_num)\n",
    "    arr_loss.append(total_loss/total_num)\n",
    "    if(arr_acc.__len__() > 1): \n",
    "        show_image_mask(arr_acc, arr_loss, 'Multiple Line Plots')\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "print('Task completed!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
